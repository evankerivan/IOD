{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MV1ykjySSrEu"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42orCR4NSrEw"
   },
   "source": [
    "# Lab 5.1\n",
    "# *Logistic Regression*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6dger9XSrEz"
   },
   "source": [
    "## Predicting Survival on the Titanic\n",
    "\n",
    "The Titanic sank during her maiden voyage after colliding with an iceberg (April 15, 1912). Due to a commercial decision there were insufficient lifeboats, a fact that was partially responsible for the loss 1,502 out of 2,224 passengers and crew.\n",
    "\n",
    "The Titanic dataset incorporates many features of typical real-world problems: a mixture of continuous and discrete features, missing data, linear covariance, and an element of random chance. Predicting survival therefore involves many practical data science skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BpW4z29ASrE1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSpp7YdtSrE8"
   },
   "source": [
    "### 1. Load Data\n",
    "\n",
    "Load the `titanic.csv` file into a DataFrame named \"titanic\", with index column = `PassengerId`. Display the head of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GXnrsCXeSrE-"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'titanic_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ANSWER\u001b[39;00m\n\u001b[1;32m      2\u001b[0m titanic_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitanic_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(titanic_csv)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanic_train.csv'"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "titanic_csv = 'titanic_train.csv'\n",
    "df=pd.read_csv(titanic_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BA8iN36rSrFE"
   },
   "source": [
    "Why would we want to set an index column based on `PassengerId`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwYgjo5JSrFG"
   },
   "source": [
    "ANSWER: This column is the key to training and testing our model. We use it to partition the dataset and to test the predictions of our model against known outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KELa83wYO5Z"
   },
   "source": [
    "<a name=\"datadictionary\"></a>\n",
    "### 2. Data Dictionary\n",
    "\n",
    "If a data dictionary is available, it is handy to include it in the notebook for reference:\n",
    "\n",
    "| Variable |                                 Definition | Key                                            |\n",
    "|----------|-------------------------------------------:|------------------------------------------------|\n",
    "| Survival | Survival                                   | 0 = No, 1 = Yes                                |\n",
    "| Pclass   | Ticket class                               | 1 = 1st, 2 = 2nd, 3 = 3rd                      |\n",
    "| Sex      | Sex                                        |                                                |\n",
    "| Age      | Age in years                               |                                                |\n",
    "| SibSp    | # of siblings / spouses aboard the Titanic |                                                |\n",
    "| Parch    | # of parents / children aboard the Titanic |                                                |\n",
    "| Ticket   | Ticket number                              |                                                |\n",
    "| Fare     | Passenger fare                             |                                                |\n",
    "| Cabin    | Cabin number                               |                                                |\n",
    "| Embarked | Port of Embarkation                        | C = Cherbourg, Q = Queenstown, S = Southampton |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CM_PnS0YO5a"
   },
   "source": [
    "### 2. EDA\n",
    "\n",
    "Explore dataset. Find features to predict `Survived`. Get rid of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-nj-5WrYO5b"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxrHcNYzSrFN"
   },
   "source": [
    "### 3. Numerical Predictors Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWs3gb8KSrFP"
   },
   "source": [
    "#### 3.1. Set Target and Features\n",
    "\n",
    "To begin, let's try a model based on the passenger class (`Pclass`) and parents/children features (`Parch`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtE4swCPtZAi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ILBoBYUYO5g"
   },
   "source": [
    "#### 3.2 Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kc2wfIDqSrFT"
   },
   "source": [
    "Split the data into training and testing subsets:\n",
    "\n",
    "- Use `random_state` = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CbfZLOdRSrFU"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8p1bdc1SrFW"
   },
   "source": [
    "#### 3.3. Build Model\n",
    "\n",
    "Prepare a model by creating an instance of the `LogisticRegression` class from the `sklearn.linear_model` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIhxqfrXSrFY"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJNFicg9SrFa"
   },
   "source": [
    "Now train it on the training data subset, using the `fit` method of the model object (Nb. by default, `fit` will print the hyperparameters of the model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzefYEzfSrFb"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# Fit Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsfC92SgSrFd"
   },
   "source": [
    "The computed coefficients are an array (`coef_`) stored in the 1st element of an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kr7GMdllSrFe"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KL7uKC8USrFh"
   },
   "source": [
    "The computed intercept (`intercept_`) is the 1st element of another array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4TudzIpjSrFi"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSc0PEbjSrFk"
   },
   "source": [
    "We can create tuples of the predictor names and coefficients like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DlaUpqxRSrFk"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "print(set(zip(feature_cols, model.coef_[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duCXO8aqSrFm"
   },
   "source": [
    "If we want formatted output, here is a neat way to list the coefficients by predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jiz-vjACSrFm"
   },
   "outputs": [],
   "source": [
    "for col in zip(X_train.columns, model.coef_[0]):\n",
    "    print('{:<10s}  {:+.06f}'.format(col[0], col[1]))  # Nb. increase 10 for longer names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65YucOmmSrFo"
   },
   "source": [
    "This result implies that survival declines with passenger class (i.e. 1st class is highest) but increases with the number of parents or children in a group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FkRLS3oSrFp"
   },
   "source": [
    "Let's see how well the model fit the training data. The accuracy `score` is the proportion of correct predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Gep5OXUSrFp"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_alclvzjSrFs"
   },
   "source": [
    "What is the accuracy `score` for the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GRLpAdmSrFt"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwgPpa5sSrFw"
   },
   "source": [
    "What can we say about this result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XUWZoBRSrFx"
   },
   "source": [
    "ANSWER\n",
    "- ...\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBWjeIE2YO6D"
   },
   "source": [
    "#### 3.4. Add `AGE` as Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rxmg3b2wSrFy"
   },
   "source": [
    "Let's include `Age` in the model. As we know from our EDA, this feature has many missing values. We don't want to throw away so many rows, so we will replace `NA` values with imputed values (e.g. the overall mean age):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IVfjTrF8SrFy"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVSXN-tfYO6J"
   },
   "outputs": [],
   "source": [
    "# Build Model\n",
    "\n",
    "# Fit Model\n",
    "\n",
    "# Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6_aYK1oSrF0"
   },
   "source": [
    "So, including age did little to reduce the variance in our model. Why might this be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1pzei3QSrF1"
   },
   "source": [
    "ANSWER\n",
    "\n",
    "- ...\n",
    "- ...\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPLvK9s2SrF1"
   },
   "source": [
    "Let's see where the model is going wrong by showing the Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAzihOU2SrF1"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-mclQOiSrF3"
   },
   "source": [
    "Nb. Here is how `confusion_matrix` arranges its output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QquT0zbNSrF4",
    "outputId": "bc777d64-736a-4bc3-bcef-8edaa99caafe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['TN' 'FP']\n",
      " ['FN' 'TP']]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray([['TN', 'FP'], ['FN', 'TP']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9sT-8GqSrF6"
   },
   "source": [
    "Which type of error is more prevalent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E08zup6gSrF7"
   },
   "source": [
    "ANSWER: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOPBQRsGSrF8"
   },
   "source": [
    "Maybe we aren't using the right cut-off value. By default, we are predicting that `Survival` = True if the probability >= 0.5, but we could use a different threshold. The ROC curve helps us decide (as well as showing us how good our predictive model really is):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqqqTVZCSrF9"
   },
   "outputs": [],
   "source": [
    "# Generate the prediction values for each of the test observations using predict_proba() function rather than just predict\n",
    "preds = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Store the false positive rate(fpr), true positive rate (tpr) in vectors for use in the graph\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, preds)\n",
    "\n",
    "# Store the Area Under the Curve (AUC) so we can annotate our graph with this metric\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC Curve\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw = lw, label = 'ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color = 'navy', lw = lw, linestyle = '--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpOA8_TFSrF_"
   },
   "source": [
    "### 4. Including Categorical Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp8r1ePeSrF_"
   },
   "source": [
    "So far, we've only used numerical features for prediction. Let's convert the character features to dummy variables so we can include them in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cbwHVP-bSrGA"
   },
   "outputs": [],
   "source": [
    "titanic_with_dummies = pd.get_dummies(data = titanic, columns = ['Sex', 'Embarked', 'Pclass'],\n",
    "                                      prefix = ['Sex', 'Embarked', 'Pclass'] )\n",
    "titanic_with_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_WnnEWdSrGB"
   },
   "source": [
    "So, this created a column for every possible value of every categorical variable. (A more compact approach would have been to reduce the number of dummy variables by one for each feature, so that the first variable from each captures two possible states.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWjijSClSrGB"
   },
   "source": [
    "Now that we have data on sex, embarkation port, and passenger class we can try to improve our `Age` imputation by stratifying it by the means of groups within the passenger population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYTqaSTySrGC"
   },
   "outputs": [],
   "source": [
    "titanic_with_dummies['Age'] = titanic_with_dummies[[\"Age\", \"Parch\", \"Sex_male\", \"Pclass_1\", \"Pclass_2\"]].groupby([\"Parch\", \"Sex_male\", \"Pclass_1\", \"Pclass_2\"])[\"Age\"].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMt6G9JYSrGE"
   },
   "source": [
    "Now train the model using the expanded set of predictors and compute the accuracy score for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSX26hn-SrGE"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# Set Feature Both Numerical, Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLTPHMa2SrGF"
   },
   "source": [
    "Plot the ROC curve for the new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqkichKQYO6l"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlT5P8TfSrGH"
   },
   "source": [
    "Can we improve the model by including the remaining features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpqcaw8NYO6p"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHrtlx8tSrGP"
   },
   "source": [
    "## Homework\n",
    "\n",
    "1. Remove the `random_state` parameter (if you have used), so that the data partition will be different every time, and run through the final modelling process a few times. Do the results change?\n",
    "\n",
    "2. Use cross-validation to assess the quality of the model when overfitting is controlled. Does the accuracy improve?\n",
    "\n",
    "3. Look at the `fpr` & `tpr` vectors for the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2024 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
